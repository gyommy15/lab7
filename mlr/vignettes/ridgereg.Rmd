---
title: "ridgereg"
author: "Josh Hyungyum Kim"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r}
library(mlbench)
library(caret)
library(mlr)
data("BostonHousing")
```

# Introduction
In this vignette, it will be shown how to do a simple prediction problem using ridgereg() function in the package "mlr" with the data _BostonHousing_ found in the mlbench package. The dataset consists of 506 observations of 14 variables. The median value of house price in $1000s, denoted by MEDV, is the outcome or the target variable in our model. Below is a brief description of each feature and the outcome in our dataset:

1. CRIM \-\-\- per capita crime rate by town
2. ZN \-\-\- proportion of residential land zoned for lots over 25,000 sq.ft
3. INDUS \-\-\- proportion of non-retail business acres per town
4. CHAS \-\-\- Charles River dummy variable (1 if tract bounds river; else 0)
5. NOX \-\-\- nitric oxides concentration (parts per 10 million)
6. RM \-\-\- average number of rooms per dwelling
7. AGE \-\-\- proportion of owner-occupied units built prior to 1940
8. DIS \-\-\- weighted distances to five Boston employment centres
9. RAD \-\-\- index of accessibility to radial highways
10. TAX \-\-\- full-value property-tax rate per $10,000
11. PTRATIO \-\-\- pupil-teacher ratio by town
12. B \-\-\- 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town
13. LSTAT \-\-\- % lower status of the population
14. MEDV \-\-\- Median value of owner-occupied homes in $1000â€™s

First 6 rows of the dataset are shown below:
```{r}
head(BostonHousing)
```


###1. Divide the BostonHousing data into a test and training dataset
```{r}
set.seed(12345)
inTrain <- createDataPartition(BostonHousing$medv, p = .8, list = FALSE)
training <- BostonHousing[ inTrain,]
testing  <- BostonHousing[-inTrain,]

#For the 10-fold cross-validation
ctrl <- trainControl(method = "repeatedcv",
  number = 10, # k=10
  repeats = 10) # repeat 10 times
```

###2-1. Fit a linear regression model.
```{r}
set.seed(12345)
lm <- caret::train(medv ~ ., 
            data = training,
            method = "lm",
            trControl = ctrl,
            preProc = "scale")
lm
```

###2-2. Fit a linear regression model with forward selection.
```{r}
set.seed(12345)
lflmGrid <- expand.grid(nvmax=1:(ncol(training)-1))
lflm <- caret::train(medv ~ ., 
              data = training,
              method = "leapForward",
              trControl = ctrl,
              tuneGrid = lflmGrid,
              preProc = "scale")

lflm

summary(lflm)
```

###3. Evaluate the performance of this model on the training dataset.
Based on the RMSE results above, regression model with 10 factors(excluding indus, chas1, age) is slightly better than with all 13 factors model. Though the difference is very small, model with 10 factors is simpler. For a detailed evaluation, residual vs fitted plot should be drawn.

```{r, fig.height= 7, fig.width= 7 }
p_data <- as.data.frame(cbind(predict(lflm), scale(resid(lflm))))

plot1 <- ggplot(p_data, aes(x = p_data[,1], y = p_data[,2])) + geom_point() +
          geom_smooth(method = "loess", color = "red") + xlab("Fitted") +
          ylab("Residuals") + ggtitle("Resid vs Fitted with 10 factors") +
          theme(plot.title = element_text(hjust = 0.5))

plot(plot1)
```

Above plot implies a clustering tendency of data and further investigation is needed to select a better model to fit this data. 

###4. Fit a ridge regression model using ridgereg() function in mlr package.
```{r}
#To use rigdereg() function
rglm <- list(type=c("Classification", "Regression"),
            library="mlr",
            loop=NULL,
            prob=NULL)

#Parameter setting
rglm$label<-"Ridge regression by mlr package"

rglm$parameters <- data.frame(parameter = "lambda",
                  class = "numeric",
                  label = "lambda")

rglm$fit <- function(x, y, wts, param, lev, last, classProbs, ...) { 
  
  rg_data <- as.data.frame(x)
  rg_data$.outcome <- y
  
  rgrf <- ridgereg$new(rg_data$.outcome ~ ., data = rg_data, lambda=param$lambda, ...)
  
  # rgrf <- ridgereg$new(formula = formula, data = rg_data, lambda = param$lambda)
  rgrf
 }
 
rglm$predict <- function(modelFit, newdata, preProc=NULL, submodels = NULL){
  predict(modelFit, newdata)
}

rglm$sort  <- function(x) x[order(x$lambda),]


rglm$grid <- function(x, y, len=NULL, search="grid"){
  data.frame(lambda=1)
}
```


```{r}
set.seed(12345)
rglm_fit <- caret::train(medv ~ .,
                  data = training,
                  method = rglm,
                  # trControl = ctrl,
                  preProcess = "scale")

rglm_fit
```

